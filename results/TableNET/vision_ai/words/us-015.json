{"text": "Item Property duri Clarity or relevance PRO Response range Reason for Change or Deletion Variability Reported as not relevant by a large segment of the target population Reproducibility Generates an unacceptably large amount of missing data points Inter-item correlation Generates many questions or requests for clarification from patients as they complete the PRO instrument Ability to detect change Patients interpret items and responses in a way that is inconsistent with the PRO instrument's conceptual framework Item discrimination A high percent of patients respond at the floor (response scale's worst end) or ceiling (response scale's optimal end) Redundancy Patients note that none of the response choices applies to them Recall period Distribution of item responses is highly skewed All patients give the same answer (i.e., no variance) Most patients choose only one response choice Differences among patients are not detected when important differences are known Unstable scores over time when there is no logical reason for variation from one assessment to the next Item highly correlated (redundant) with other items in the same concept of interest Item is not sensitive (i.e., does not change when there is a known change in the concepts of interest) Item is highly correlated with measures of concepts other than the one it is intended to measure Item does not show variability in relation to some known population characteristics (i.e., severity level, classification of condition, or other known characteristic) Item duplicates information collected with other items that have equal or better measurement properties The population, disease state, or application of the instrument can affect the appropriateness of the recall period Measurement \u0422\u0443\u0440\u0435 als Property Reliability Test-retest or intra- What Is Assessed? Validity interviewer reliability (for FDA Review Considerations Ability change interviewer-administered Stability of scores over time when no change is expected in the concept of interest to detect PROS only) Internal consistency Intraclass correlation coefficient Inter-interviewer reliability (for interviewer-administered PROS only) Time period of assessment Content validity Cronbach's alpha for summary scores Construct validity Extent to which items comprising a scale measure the same concept Item-total correlations Intercorrelation of items that contribute to a score Internal consistency Agreement among responses when is administered by two or more different PRO Interclass correlation coefficient interviewers Evidence that the instrument measures the Derivation of all items concept of interest including evidence from qualitative studies that the items and domains of an instrument are appropriate and comprehensive relative to its intended measurement concept, population, and use. Testing other measurement properties will not replace or rectify problems with content validity. Evidence that relationships among items, domains, and concepts conform to a priori hypotheses concerning logical relationships that should exi Qualitative interview schedule Interview or focus group transcripts Items derived from the transcripts Composition of patients used to develop content Cognitive interview transcripts to evaluate patient understanding Strength of correlation testing a priori hypotheses (discriminant and convergent validity) Degree to which the PRO instrument can distinguish among groups hypothesized a priori to be different (known groups validity) with measures of related concepts or scores produced in similar or diverse patient groups Evidence that a PRO instrument can identify Within person change over time Effect size statistic differences in scores over time in individuals or groups (similar to those in the clinical trials) who have changed with respect to the measurement concept", "cellCount": 71}