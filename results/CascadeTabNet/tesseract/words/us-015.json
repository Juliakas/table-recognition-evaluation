{"text": "Measurement Property Reliability Test-retest or intra- interviewer reliability (for interviewer-administered PROs only) internal consistency inter-interviewer reliability (for interviewer-administered PROs only) Construct validity Stability of scores over time when no change is expected in the concept of interest Extent to which items comprising a scale measure the same concept Intercorrelation of items that contribute to a score Internal consistency Agreement among responses when the PRO is administered by two or more different interviewers Evidence that the instrument measures the concept of interest including evidence from qualitative studies that the items and domains of an instrument are appropriate and comprehensive relative to its intended measurement concept, population, and use. Testing other measurement properties will not replace or rectify problems with content validity. Evidence that relationships among items, domains, and concepts conform to a priori hypotheses concerning logical relationships that should exist with measures of related concepts or scores produced in similar or diverse patient groups KIA Review Considerations e Intraclass correlation coefficient e Time period of assessment Cronbach s alpha for summary scores e Ttem-total correlations e # Interclass correlation coetfticient Derivation of all items Qualitative interview schedule Interview or focus group transcripts Items derived from the transcripts Composition of patients used to develop content Cognitive interview transcripts to evaluate patient understanding Strength of correlation testing a priori hypotheses (discriminant and convergent validity) Degree to which the PRO instrument can distinguish among groups hypothesized a priori to be different (known groups validity) ", "cellCount": 21}