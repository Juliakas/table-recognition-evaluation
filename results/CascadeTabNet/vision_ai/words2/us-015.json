{"text": "Item Property Reason for Change or Deletion Clarity or relevance Reported as not relevant by a large segment of the target population Generates an unacceptably large amount of missing data points Generates many questions or requests for clarification from patients as they complete the PRO instrument Patients interpret items and responses in a way that is inconsistent with the PRO instrument's conceptual framework Response range A high percent of patients respond at the floor (response scale's worst end) or ceiling (response scale's optimal end) Patients note that none of the response choices applies to them Distribution of item responses is highly skewed Variability All patients give the same answer (i.e., no variance) Most patients choose only one response choice Differences among patients are not detected when important differences are known Reproducibility Unstable scores over time when there is no logical reason for variation from one assessment to the next Inter-item correlation Item highly correlated (redundant) with other items in the same concept of interest Ability to detect change Item is not sensitive (i.e., does not change when there is a known change in the concepts of interest) Item discrimination Item is highly correlated with measures of concepts other than the one it is intended to measure Item does not show variability in relation to some known population characteristics (i.e., severity level, classification of condition, or other known characteristic) Redundancy Item duplicates information collected with other items that have equal or better measurement properties Recall period The population, disease state, or application of the instrument can affect the of the reooll noried Item Property Reason for Change or Deletion Clarity or relevance Reported as not relevant by a large segment of the target population Generates an unacceptably large amount of missing data points Generates many questions or requests for clarification from patients as they complete the PRO instrument Patients interpret items and responses in a way that is inconsistent with the PRO instrument's conceptual framework Response range A high percent of patients respond at the floor (response scale's worst end) or ceiling (response scale's optimal end) Patients note that none of the response choices applies to them Distribution of item responses is highly skewed Variability All patients give the same answer (i.e., no variance) Most patients choose only one response choice Differences among patients are not detected when important differences are known Reproducibility Unstable scores over time when there is no logical reason for variation from one assessment to the next Inter-item correlation Item highly correlated (redundant) with other items in the same concept of interest Ability to detect change Item is not sensitive (i.e., does not change when there is a known change in the concepts of interest) Item discrimination Item is highly correlated with measures of concepts other than the one it is intended to measure Item does not show variability in relation to some known population characteristics (i.e., severity level, classification of condition, or other known characteristic) Redundancy Item duplicates information collected with other items that have equal or better measurement properties Recall period The population, disease state, or application of the instrument can affect the appropriateness of the recall period Measurement \u0422\u0443\u0440\u0435 What Is Assessed? FDA Review Considerations Property Reliability Test-retest or intra- Stability of scores over time when no change is expected in the concept of interest Intraclass correlation coefficient interviewer reliability (for Time period of assessment interviewer-administered PROS only) Internal consistency Cronbach's alpha for summary scores Extent to which items comprising a scale measure the same concept Item-total correlations Intercorrelation of items that contribute to a score Inter-interviewer reliability (for interviewer-administered PROS only) Internal consistency Agreement among responses when the PRO is administered by two or more different Interclass correlation coefficient interviewers Validity Content validity Evidence that the instrument measures the Derivation of all items concept of interest including evidence from qualitative studies that the items and domains of an instrument are appropriate and comprehensive relative to its intended measurement concept, population, and use. Testing other measurement properties will not replace or rectify problems with content validity. Evidence that relationships among items, domains, and concepts conform to a priori hypotheses concerning logical relationships Qualitative interview schedule Interview or focus group transcripts Items derived from the transcripts Composition of patients used to develop content Cognitive interview transcripts to evaluate patient understanding Construct validity Strength of correlation testing a priori hypotheses (discriminant and convergent validity) Degree to which the PRO instrument can distinguish that should exist with measures of related among groups hypothesized a priori to be different (known groups validity) concepts or scores produced in similar or diverse patient groups Ability to detect change Evidence that a PRO instrument can identify Within person change over time Effect size statistic differences in scores over time in individuals or groups (similar to those in the clinical trials) who have changed with respect to the measurement concept Table 2. Measurement Properties Considered in the Review of PRO Instruments Used in Clinical Trials Measurement \u0422\u0443\u0440\u0435 What Is Assessed? FDA Review Considerations Property Reliability Test-retest or intra- Stability of scores over time when no change is expected in the concept of interest Intraclass correlation coefficient interviewer reliability (for Time period of assessment interviewer-administered PROS only) Internal consistency Cronbach's alpha for summary scores Extent to which items comprising a scale measure the same concept Item-total correlations Intercorrelation of items that contribute to a score Inter-interviewer reliability (for interviewer-administered PROS only) Internal consistency Agreement among responses when the PRO is administered by two or more different interviewers Interclass correlation coefficient Validity Content validity Evidence that the instrument measures the Derivation of all items concept of interest including evidence from qualitative studies that the items and domains of an instrument are appropriate and comprehensive relative to its intended measurement concept, population, and use. Testing other measurement properties will not replace or rectify problems with content validity. Evidence that relationships among items, domains, and concepts conform to a priori hypotheses concerning logical relationships Qualitative interview schedule Interview or focus group transcripts Items derived from the transcripts Composition of patients used to develop content Cognitive interview transcripts to evaluate patient understanding Construct validity Strength of correlation testing a priori hypotheses (discriminant and convergent validity) Degree to which the PRO instrument can distinguish among groups hypothesized a priori to be different (known groups validity) that should exist with measures of related concepts or scores produced in similar or diverse patient groups Evidence that a PRO instrument can identify Ability to detect change Within person change over time differences in scores over time in individuals Effect size statistic or groups (similar to those in the clinical trials) who have changed with respect to the measurement concept", "cellCount": 0}